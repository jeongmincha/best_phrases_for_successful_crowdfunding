{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('./data/3-15_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['percentage'] = csv['usd_pledged'] / csv['goal']\n",
    "csv['duration'] = csv['deadline'] - csv['launched_at']\n",
    "\n",
    "def boolean_to_number(x):\n",
    "    if x is True:\n",
    "        return 1\n",
    "    elif x is False:\n",
    "        return 0\n",
    "\n",
    "csv['spotlight_num'] = csv['spotlight'].apply(boolean_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = ['usd_pledged', 'backers_count', 'percentage']\n",
    "input_features = ['goal', 'deadline', 'launched_at', 'duration', 'spotlight_num'] + list(csv.columns[33:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = csv[input_features] # 44930 (5 + 44925)\n",
    "y = csv[target_features] # 3\n",
    "\n",
    "print (\"... Normalize features\")\n",
    "min_max_scalar = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scalar.fit_transform(x)\n",
    "x_scaled = pd.DataFrame(x_scaled)\n",
    "y_scaled = min_max_scalar.fit_transform(y)\n",
    "y_scaled = pd.DataFrame(y_scaled)\n",
    "\n",
    "print (\"... Training\")\n",
    "reg = linear_model.Ridge(alpha=.5)\n",
    "reg.fit(x_scaled, y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(reg.coef_, columns=input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx = 2\n",
    "mx = max(reg.coef_[target_idx])\n",
    "for idx in range(len(reg.coef_[target_idx])):\n",
    "    if reg.coef_[target_idx][idx] == mx:\n",
    "        print (idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "word_list.extend(open('unigram_list.txt').readlines())\n",
    "word_list.extend(open('bigram_list.txt').readlines())\n",
    "word_list.extend(open('trigram_list.txt').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_view(top_idxs, lst):\n",
    "    top_n_lst = []\n",
    "    for idx in top_idxs:\n",
    "        if idx.isdigit():\n",
    "            top_n_lst.append(lst[int(idx)])\n",
    "        else:\n",
    "            top_n_lst.append(idx)\n",
    "    return top_n_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (coef.transpose().nlargest(50, 0)[0].index)\n",
    "print (coef.transpose().nlargest(50, 0)[0].values)\n",
    "\n",
    "print (coef.transpose().nsmallest(50, 0)[0].index)\n",
    "print (coef.transpose().nsmallest(50, 0)[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# for target_idx in range(3):\n",
    "target_idx = \n",
    "top_n = 50\n",
    "top_n_idxs = coef.transpose().nsmallest(top_n, target_idx)[target_idx].index\n",
    "# top_n_idxs = coef.transpose().nlargest(top_n, target_idx)[target_idx].index\n",
    "print (\"target variable: \", target_features[target_idx])\n",
    "with open('smallest_50_percentage.pickle', 'wb') as handle:\n",
    "    pickle.dump(list_view(top_n_idxs, word_list), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print (list_view(top_n_idxs, word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "lst = []\n",
    "for file in glob.glob('./data_feature/*.csv'):\n",
    "    df = pd.read_csv(file, index_col=None, header=0)\n",
    "    lst.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['percentage'] = df['usd_pledged'] / df['goal']\n",
    "df['duration'] = df['deadline'] - df['launched_at']\n",
    "\n",
    "def boolean_to_number(x):\n",
    "    if x is True:\n",
    "        return 1\n",
    "    elif x is False:\n",
    "        return 0\n",
    "\n",
    "df['spotlight_num'] = df['spotlight'].apply(boolean_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = ['usd_pledged', 'backers_count', 'percentage']\n",
    "input_features = ['goal', 'deadline', 'launched_at', 'duration', 'spotlight_num'] + list(df.columns[33:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "x = df[input_features]\n",
    "y = df[target_features]\n",
    "\n",
    "ratio = 0.75\n",
    "dev_split = int(len(x) * ratio)\n",
    "train_x = x[:dev_split]\n",
    "train_y = y[:dev_split]\n",
    "test_x = x[dev_split:]\n",
    "test_y = y[dev_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"... Normalize features\")\n",
    "def normalize_features(x):\n",
    "    from sklearn import preprocessing\n",
    "    min_max_scalar = preprocessing.MinMaxScaler()    \n",
    "    return pd.DataFrame(min_max_scalar.fit_transform(x))\n",
    "\n",
    "train_x_scaled = normalize_features(train_x)\n",
    "train_y_scaled = normalize_features(train_y)\n",
    "test_x_scaled = normalize_features(test_x)\n",
    "test_y_scaled = normalize_features(test_y)\n",
    "\n",
    "print (\"... Training\")\n",
    "reg = linear_model.Ridge(alpha=.5)\n",
    "reg.fit(train_x_scaled, train_y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(test_x_scaled, test_y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(reg.coef_, columns=input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (coef.transpose().nlargest(50, 0)[0].index)\n",
    "print (coef.transpose().nlargest(50, 0)[0].values)\n",
    "\n",
    "print (coef.transpose().nsmallest(50, 0)[0].index)\n",
    "print (coef.transpose().nsmallest(50, 0)[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "word_list.extend(open('./data_feature/unigram_list.txt').readlines())\n",
    "word_list.extend(open('./data_feature/bigram_list.txt').readlines())\n",
    "word_list.extend(open('./data_feature/trigram_list.txt').readlines())\n",
    "\n",
    "def list_view(top_idxs, lst):\n",
    "    top_n_lst = []\n",
    "    for idx in top_idxs:\n",
    "        if idx.isdigit():\n",
    "            top_n_lst.append(lst[int(idx)])\n",
    "        else:\n",
    "            top_n_lst.append(idx)\n",
    "    return top_n_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# for target_idx in range(3):\n",
    "target_idx = 0\n",
    "top_n = 50\n",
    "# top_n_idxs = coef.transpose().nsmallest(top_n, target_idx)[target_idx].index\n",
    "top_n_idxs = coef.transpose().nlargest(top_n, target_idx)[target_idx].index\n",
    "print (\"target variable: \", target_features[target_idx])\n",
    "# with open('smallest_50_percentage.pickle', 'wb') as handle:\n",
    "#     pickle.dump(list_view(top_n_idxs, word_list), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print (list_view(top_n_idxs, word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = pd.read_csv('./data_feature/feature_Kickstarter001_2.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
